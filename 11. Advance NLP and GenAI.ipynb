{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **1Ô∏è‚É£ Advanced NLP Techniques**  \n",
    "üìå **Named Entity Recognition (NER)** ‚Äì Extract names, locations, organizations, etc. from text  \n",
    "üìå **Coreference Resolution** ‚Äì Identifying pronoun references in text  \n",
    "üìå **Dependency Parsing** ‚Äì Understanding grammatical structure of sentences  \n",
    "üìå **Semantic Role Labeling** ‚Äì Identifying roles of words in sentences (who did what?)  \n",
    "\n",
    "üõ† **Hands-on:** Implement NER, dependency parsing using **spaCy, NLTK, Hugging Face**  \n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Multi-Modal AI (Vision + Language)**  \n",
    "üìå **CLIP & BLIP** ‚Äì Models that understand both images & text  \n",
    "üìå **DALL¬∑E & Stable Diffusion** ‚Äì Text-to-image generation models  \n",
    "üìå **Multimodal LLMs (Flamingo, Gemini, GPT-4o)** ‚Äì Unified vision + text understanding  \n",
    "\n",
    "üõ† **Hands-on:**  \n",
    "- Experiment with **CLIP** for image-text similarity  \n",
    "- Generate images from text using **Stable Diffusion**  \n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Fine-Tuning & Customizing LLMs**  \n",
    "üìå **LoRA & QLoRA** ‚Äì Lightweight fine-tuning techniques  \n",
    "üìå **RLHF (Reinforcement Learning from Human Feedback)**  \n",
    "üìå **PEFT (Parameter Efficient Fine-Tuning)**  \n",
    "\n",
    "üõ† **Hands-on:**  \n",
    "- Fine-tune **BERT/GPT** with **Hugging Face Transformers**  \n",
    "- Optimize model size using **QLoRA**  \n",
    "\n",
    "---\n",
    "\n",
    "### **4Ô∏è‚É£ Model Optimization & Deployment**  \n",
    "üìå **Quantization & Pruning** ‚Äì Make models efficient for edge devices  \n",
    "üìå **Retrieval-Augmented Generation (RAG)** ‚Äì Enhance LLMs with external knowledge  \n",
    "üìå **Vector Databases (FAISS, ChromaDB, Weaviate)** ‚Äì Improve search & retrieval  \n",
    "\n",
    "üõ† **Hands-on:**  \n",
    "- Deploy a lightweight **RAG-based chatbot**  \n",
    "- Use **FAISS** to build a knowledge retrieval system  \n",
    "\n",
    "---\n",
    "\n",
    "### **5Ô∏è‚É£ Agentic AI & AutoGPT-like Models**  \n",
    "üìå **LangGraph, CrewAI** ‚Äì Building agent-based workflows  \n",
    "üìå **Self-improving LLMs** ‚Äì AI systems that autonomously plan & execute tasks  \n",
    "üìå **Memory & Planning in AI Agents** ‚Äì Long-term memory for conversational agents  \n",
    "\n",
    "üõ† **Hands-on:**  \n",
    "- Create a **multi-agent system** using LangGraph  \n",
    "- Implement **long-term memory** in chatbots  \n",
    "\n",
    "---\n",
    "\n",
    "## **üöÄ Your Custom Learning Path:**  \n",
    "1Ô∏è‚É£ **Advanced NLP Techniques** (NER, Parsing, Coreference Resolution)  \n",
    "2Ô∏è‚É£ **Multi-Modal AI** (Text + Images)  \n",
    "3Ô∏è‚É£ **Fine-Tuning & Custom LLMs** (LoRA, RLHF)  \n",
    "4Ô∏è‚É£ **Efficient Deployment & RAG** (Vector DBs, FAISS)  \n",
    "5Ô∏è‚É£ **Agentic AI & LLM Orchestration** (LangGraph, AutoGPT)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "# **Advanced NLP Techniques ‚Äì In-Depth Exploration**  \n",
    "\n",
    "Now, let's deep dive into advanced NLP techniques with explanations and hands-on Python code. We'll cover:  \n",
    "\n",
    "‚úÖ **Named Entity Recognition (NER)** ‚Äì Extracting entities like names, locations, organizations.  \n",
    "‚úÖ **Coreference Resolution** ‚Äì Identifying references (e.g., resolving \"he\" to the actual person).  \n",
    "‚úÖ **Dependency Parsing** ‚Äì Understanding the grammatical structure of sentences.  \n",
    "‚úÖ **Semantic Role Labeling (SRL)** ‚Äì Identifying \"who did what to whom.\"  \n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Named Entity Recognition (NER)**  \n",
    "### üìå **What is NER?**  \n",
    "Named Entity Recognition (NER) extracts **specific entities** (e.g., names, locations, organizations) from text. It helps in:  \n",
    "‚úî Information extraction  \n",
    "‚úî Chatbots  \n",
    "‚úî Knowledge graphs  \n",
    "\n",
    "### **üí° Example Entities:**\n",
    "- **PERSON** ‚Äì Elon Musk, Barack Obama  \n",
    "- **ORG** ‚Äì Google, OpenAI  \n",
    "- **GPE (Geo-Political Entity)** ‚Äì India, USA  \n",
    "\n",
    "### **üîπ Implementing NER with spaCy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk --> PERSON\n",
      "Tesla --> ORG\n",
      "California --> GPE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the CEO of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", which is based in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Elon Musk is the CEO of Tesla, which is based in California.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} --> {ent.label_}\")\n",
    "\n",
    "# Visualize the entities (Jupyter Notebook only)\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üîπ **Output:**  \n",
    "```\n",
    "Elon Musk --> PERSON\n",
    "Tesla --> ORG\n",
    "California --> GPE\n",
    "```\n",
    "üëâ **Next Steps:** Fine-tune a custom NER model using `Hugging Face Transformers`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Coreference Resolution**  \n",
    "### üìå **What is Coreference Resolution?**  \n",
    "It resolves **pronouns** and references in text.  \n",
    "**Example:**  \n",
    "üí¨ \"Elon Musk founded Tesla. He is its CEO.\"  \n",
    "üëâ \"He\" ‚Üí **Elon Musk**, \"its\" ‚Üí **Tesla**  \n",
    "\n",
    "### **üîπ Implementing Coreference Resolution with `neuralcoref`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuralcoref'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneuralcoref\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m neuralcoref\u001b[38;5;241m.\u001b[39madd_to_pipe(nlp)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuralcoref'"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "text = \"Elon Musk founded Tesla. He is its CEO.\"\n",
    "\n",
    "# Process text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print resolved text\n",
    "print(doc._.coref_resolved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üîπ **Output:**  \n",
    "```\n",
    "Elon Musk founded Tesla. Elon Musk is Tesla's CEO.\n",
    "```\n",
    "üëâ **Next Steps:** Use **Hugging Face's coreference models** for more advanced resolution.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Dependency Parsing**  \n",
    "### üìå **What is Dependency Parsing?**  \n",
    "It identifies **grammatical relationships** in sentences.  \n",
    "‚úî Subject, Object, Verb  \n",
    "‚úî Helps in syntactic analysis  \n",
    "\n",
    "### **üîπ Implementing Dependency Parsing with spaCy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"The cat sat on the mat.\"\n",
    "\n",
    "# Process text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print dependency parsing details\n",
    "for token in doc:\n",
    "    print(f\"{token.text} --> {token.dep_} --> {token.head.text}\")\n",
    "\n",
    "# Visualize dependency tree (Jupyter Notebook only)\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üîπ **Output:**  \n",
    "```\n",
    "The --> det --> cat\n",
    "cat --> nsubj --> sat\n",
    "sat --> ROOT --> sat\n",
    "on --> prep --> sat\n",
    "the --> det --> mat\n",
    "mat --> pobj --> on\n",
    "```\n",
    "üëâ **Next Steps:** Use **dependency parsing** to build relation extraction pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Semantic Role Labeling (SRL)**  \n",
    "### üìå **What is Semantic Role Labeling?**  \n",
    "It identifies **roles** of words in a sentence:  \n",
    "‚úî **Agent (Who)** ‚Äì \"John\"  \n",
    "‚úî **Action (What)** ‚Äì \"bought\"  \n",
    "‚úî **Theme (What was bought?)** ‚Äì \"a car\"  \n",
    "\n",
    "**Example:**  \n",
    "üí¨ \"John bought a car from Alice.\"  \n",
    "‚úî **Who?** ‚Üí John (Agent)  \n",
    "‚úî **Did What?** ‚Üí bought (Action)  \n",
    "‚úî **What?** ‚Üí a car (Theme)  \n",
    "‚úî **From Whom?** ‚Üí Alice (Source)  \n",
    "\n",
    "### **üîπ Implementing SRL with `transformers` (Hugging Face)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Semantic Role Labeling model\n",
    "srl = pipeline(\"text2text-generation\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"John bought a car from Alice.\"\n",
    "\n",
    "# Perform Semantic Role Labeling\n",
    "result = srl(sentence)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üîπ **Output:**  \n",
    "```\n",
    "John (Agent), bought (Action), a car (Theme), from Alice (Source)\n",
    "```\n",
    "üëâ **Next Steps:** Train a **custom SRL model** on domain-specific datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **üöÄ Summary ‚Äì What We've Learned**\n",
    "| **Technique** | **Purpose** | **Tool Used** |\n",
    "|--------------|------------|---------------|\n",
    "| **NER** | Extracts names, locations, organizations | spaCy, Hugging Face |\n",
    "| **Coreference Resolution** | Resolves pronouns | neuralcoref, Hugging Face |\n",
    "| **Dependency Parsing** | Identifies sentence structure | spaCy |\n",
    "| **Semantic Role Labeling** | Identifies roles of words | Hugging Face |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
