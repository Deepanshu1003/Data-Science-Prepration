{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Great! Let's start by building a **basic RAG (Retrieval-Augmented Generation) model** for a **trip itinerary planner**.  \n",
    "\n",
    "### **üìå Plan for Building the RAG Model**\n",
    "1Ô∏è‚É£ **Basic RAG Model**  \n",
    "   - Use **FAISS** as the vector database  \n",
    "   - Use **OpenAI (GPT-4) or Mistral** as the generator  \n",
    "   - Store & retrieve trip-related documents  \n",
    "   - Generate itinerary based on user query  \n",
    "\n",
    "2Ô∏è‚É£ **Advanced RAG Enhancements**  \n",
    "   - **Multi-hop Retrieval** (For complex queries)  \n",
    "   - **Hybrid Retrieval** (BM25 + Dense embeddings)  \n",
    "   - **Fine-tuning the retriever and LLM**  \n",
    "   - **Multi-Modal RAG** (Text + Images for travel)  \n",
    "   - **Streaming RAG** (Real-time updates on travel data)  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **üõ† Step 1: Building a Basic RAG Model**\n",
    "We will:  \n",
    "‚úÖ Load travel-related documents into FAISS  \n",
    "‚úÖ Use an embedding model (e.g., OpenAI, HuggingFace)  \n",
    "‚úÖ Retrieve relevant travel data based on user query  \n",
    "‚úÖ Generate trip plans with an LLM  \n",
    "\n",
    "Let‚Äôs build this step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Key securely from .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI Chat Model (Updated API)\n",
    "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=api_key)\n",
    "\n",
    "# Initialize OpenAI Embeddings (for Vector Search)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Travel Information (Knowledge Base)\n",
    "documents = [\n",
    "    \"Paris has beautiful landmarks like the Eiffel Tower and Louvre Museum.\",\n",
    "    \"Tokyo is known for its cherry blossoms and sushi culture.\",\n",
    "    \"New York has Times Square, Central Park, and Broadway shows.\",\n",
    "    \"Rome is famous for its ancient Colosseum and Vatican City.\",\n",
    "    \"The best time to visit Paris is in Spring or Fall.\",\n",
    "    \"A 3-day itinerary for Paris includes visits to the Eiffel Tower, Louvre, and Seine River Cruise.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a Vector Database using FAISS\n",
    "vectorstore = FAISS.from_texts(documents, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a Document Combination Chain (Fixing Previous Error)\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")  # \"stuff\" merges retrieved documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up the Retrieval-Augmented Generation (RAG) Chain\n",
    "rag_chain = RetrievalQA(combine_documents_chain=qa_chain, retriever=retriever)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Itinerary:\n",
      " I'm sorry, but I don't have information on a 3-day itinerary for Delhi in the context provided.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: User Query - Plan a trip\n",
    "query = \"Plan a 3-day trip to delhi\"\n",
    "response = rag_chain.run(query)\n",
    "\n",
    "print(\"Generated Itinerary:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **‚úÖ What This Does**\n",
    "1. **Loads travel-related documents** (Basic info about cities).  \n",
    "2. **Uses FAISS** to store & retrieve relevant travel data.  \n",
    "3. **Embeds the documents using OpenAI embeddings**.  \n",
    "4. **Uses GPT-4** to generate an itinerary.  \n",
    "\n",
    "Try running this, and let me know if you want any modifications! üöÄ  \n",
    "Next, we‚Äôll add **multi-hop retrieval** to handle more complex queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **build Hybrid RAG + Multi-Hop RAG** step by step. üöÄ  \n",
    "\n",
    "---\n",
    "\n",
    "### **üõ† Step 1: Hybrid Retrieval (BM25 + FAISS)**\n",
    "üîπ **Why?**  \n",
    "- **BM25 (Lexical)** retrieval is **good for keyword-based queries**.  \n",
    "- **FAISS (Semantic)** retrieval is **good for meaning-based queries**.  \n",
    "- **Hybrid RAG = Best of both worlds!**  \n",
    "\n",
    "üîπ **How?**  \n",
    "- Use **BM25** (`rank_bm25` library) for **keyword retrieval**.  \n",
    "- Use **FAISS** for **vector retrieval**.  \n",
    "- **Combine scores** (BM25 + FAISS) to return the best documents.\n",
    "\n",
    "---\n",
    "\n",
    "### **üõ† Step 2: Multi-Hop Retrieval (Answering Complex Queries)**\n",
    "üîπ **Why?**  \n",
    "- Some queries **require multiple retrieval steps**.  \n",
    "- Example:  \n",
    "  **‚ÄúWhat are the best tourist spots in Paris, and how do I get there?‚Äù**  \n",
    "  - **First step:** Find top tourist spots in Paris.  \n",
    "  - **Second step:** Retrieve transport options to these spots.  \n",
    "\n",
    "üîπ **How?**  \n",
    "- **Break query into sub-queries** dynamically.  \n",
    "- **Retrieve iteratively**, refining search results at each step.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **üöÄ Hybrid + Multi-Hop RAG Implementation**\n",
    "I'll now create a **Python script** combining **Hybrid Retrieval (BM25 + FAISS) + Multi-Hop Retrieval** for a **Trip Itinerary RAG**.  \n",
    "\n",
    "üîπ **Tech Stack:**  \n",
    "‚úÖ **BM25** (Lexical Search)  \n",
    "‚úÖ **FAISS** (Semantic Search)  \n",
    "‚úÖ **LangChain** (RAG Framework)  \n",
    "‚úÖ **OpenAI GPT-4** (LLM)  \n",
    "‚úÖ **FastAPI** (for future deployment)  \n",
    "\n",
    "Let's write the **Hybrid Multi-Hop RAG code now!** ‚è≥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from rank_bm25 import BM25Okapi\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load API Keys\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI Chat Model\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Documents (Trip Itinerary Data)\n",
    "def load_documents(file_path=\"data/trip_itineraries.txt\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return text_splitter.create_documents([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess Documents\n",
    "docs = load_documents()\n",
    "\n",
    "# BM25 (Lexical Search)\n",
    "tokenized_corpus = [doc.page_content.split() for doc in docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# FAISS (Vector Search)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Hybrid Retrieval (BM25 + FAISS)\n",
    "def hybrid_retrieval(query, bm25, tokenized_corpus, vectorstore, docs, top_k=3):\n",
    "    # BM25 Lexical Search\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "    bm25_docs = [docs[i] for i in bm25_top_indices]\n",
    "\n",
    "    # FAISS Semantic Search\n",
    "    faiss_docs = vectorstore.similarity_search(query, k=top_k)\n",
    "\n",
    "    # Merge Results (Handling Duplicate Documents)\n",
    "    combined_docs = {doc.page_content: doc for doc in (bm25_docs + faiss_docs)}.values()\n",
    "    return list(combined_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Multi-Hop RAG\n",
    "def multi_hop_rag(query, retriever, llm, num_hops=2):\n",
    "    intermediate_query = query\n",
    "    context = \"\"\n",
    "\n",
    "    for hop in range(num_hops):\n",
    "        retrieved_docs = retriever(intermediate_query)\n",
    "        retrieved_texts = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "        context += f\"\\n--- Retrieved Context (Hop {hop+1}) ---\\n{retrieved_texts}\\n\"\n",
    "\n",
    "        # Generate intermediate query refinement\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are an intelligent travel assistant helping plan trips.\"),\n",
    "            HumanMessage(content=f\"Given this information, refine the question: {intermediate_query}\\n{context}\")\n",
    "        ]\n",
    "        response = llm(messages)\n",
    "        intermediate_query = response.content\n",
    "\n",
    "    # Final Answer Generation\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an intelligent travel assistant.\"),\n",
    "        HumanMessage(content=f\"Using this retrieved knowledge, answer the final query: {query}\\n{context}\")\n",
    "    ]\n",
    "    final_response = llm(messages)\n",
    "\n",
    "    return final_response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hybrid Retriever Wrapper\n",
    "def hybrid_retriever(query):\n",
    "    return hybrid_retrieval(query, bm25, tokenized_corpus, vectorstore, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: The best tourist spots in Paris are the Eiffel Tower, which is best visited at sunset for a stunning view, the Louvre Museum, home to the Mona Lisa and best visited early in the morning to avoid crowds, and the Notre-Dame Cathedral, a Gothic masterpiece. Another great way to explore the city is by taking a Seine River Cruise. The fastest way to travel within Paris and reach these spots is by using the Metro.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üî• Run Multi-Hop Hybrid RAG\n",
    "query = \"What are the best tourist spots in Paris, and how do I get there?\"\n",
    "response = multi_hop_rag(query, hybrid_retriever, llm, num_hops=2)\n",
    "print(\"\\nFinal Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ‚úÖ **Hybrid + Multi-Hop RAG Features**\n",
    "1Ô∏è‚É£ **Hybrid Retrieval** ‚Üí Uses **BM25** (Lexical) + **FAISS** (Semantic)  \n",
    "2Ô∏è‚É£ **Multi-Hop Retrieval** ‚Üí Iterates query refinement for **complex questions**  \n",
    "3Ô∏è‚É£ **OpenAI GPT-4** ‚Üí Generates answers based on retrieved context  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• **Building a RAG with Online Search Integration**  \n",
    "We‚Äôll enhance our RAG model by integrating **online search tools** (DuckDuckGo, Google, or SerpAPI) to fetch **real-time data** and combine it with existing knowledge from vector search.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ RAG with Online Search + Vector Database**\n",
    "### **üõ†Ô∏è Features of This RAG**\n",
    "‚úÖ **Hybrid Retrieval**: Uses both **web search** and **vector embeddings** for retrieval.  \n",
    "‚úÖ **Online Search Tools**: Fetches the latest information from the web using **DuckDuckGo, Google, or SerpAPI**.  \n",
    "‚úÖ **Multi-Hop Querying**: Dynamically refines and improves results iteratively.  \n",
    "‚úÖ **OpenAI GPT for Answer Generation**: Uses **GPT-4** to process and synthesize responses.  \n",
    "\n",
    "---\n",
    "\n",
    "### **üöÄ Implementation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from rank_bm25 import BM25Okapi\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load API Keys\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")  # For Google Search (Optional)\n",
    "\n",
    "# Initialize OpenAI Chat Model\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Load Local Knowledge Base\n",
    "def load_documents(file_path=\"data/knowledge_base.txt\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return text_splitter.create_documents([text])\n",
    "\n",
    "docs = load_documents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Best tourist destinations in Paris:\\n1. Eiffel Tower ‚Äì Iconic landmark with breathtaking city views.\\n2. Louvre Museum ‚Äì Home to the Mona Lisa and other masterpieces.\\n3. Notre-Dame Cathedral ‚Äì A stunning Gothic cathedral.\\n4. Champs-√âlys√©es ‚Äì A famous avenue with luxury shops.\\n5. Montmartre ‚Äì A historic district known for its art scene.'),\n",
       " Document(metadata={}, page_content='Best vegetarian restaurants in New York:\\n1. Superiority Burger ‚Äì Famous for its vegetarian burgers.\\n2. Dirt Candy ‚Äì High-end restaurant with innovative vegetarian dishes.\\n3. abcV ‚Äì Organic, plant-based cuisine with a chic setting.\\n4. Jajaja ‚Äì Mexican-inspired vegan food.\\n5. Le Botaniste ‚Äì Belgian-style plant-based eatery.'),\n",
       " Document(metadata={}, page_content=\"How to travel in Paris:\\n- Metro: The Paris M√©tro is the fastest way to get around.\\n- Buses: Extensive bus network covering all areas.\\n- Biking: V√©lib' bike rental is a great option.\\n- Walking: Many attractions are within walking distance.\\n\\nTravel Tips for Paris:\\n- Best time to visit: April to June & September to November.\\n- Currency: Euro (‚Ç¨).\\n- Language: French (but English is widely understood in tourist areas).\\n- Safety: Be mindful of pickpockets in crowded areas.\"),\n",
       " Document(metadata={}, page_content='General travel safety tips:\\n- Always keep a digital copy of your passport.\\n- Use an RFID-blocking wallet for extra security.\\n- Be aware of common tourist scams in major cities.\\n- Learn basic phrases in the local language.\\n\\nTop things to do in India:\\n1. Visit the Taj Mahal in Agra.\\n2. Experience the culture in Varanasi.\\n3. Explore the palaces of Rajasthan.\\n4. Enjoy the beaches of Goa.\\n5. Go on a wildlife safari in Ranthambore.'),\n",
       " Document(metadata={}, page_content='Historical landmarks around the world:\\n1. The Great Wall of China ‚Äì A marvel of ancient engineering.\\n2. Machu Picchu ‚Äì A breathtaking Incan city in Peru.\\n3. The Pyramids of Giza ‚Äì Ancient wonders in Egypt.\\n4. Colosseum ‚Äì Rome‚Äôs iconic amphitheater.\\n5. Stonehenge ‚Äì Mysterious prehistoric stone circle in England.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ BM25 (Lexical Search)\n",
    "tokenized_corpus = [doc.page_content.split() for doc in docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# üîπ FAISS (Vector Search)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Online Search Retrieval (DuckDuckGo API)\n",
    "def web_search_duckduckgo(query, num_results=3):\n",
    "    search_url = f\"https://api.duckduckgo.com/?q={query}&format=json\"\n",
    "    response = requests.get(search_url).json()\n",
    "    results = response.get(\"RelatedTopics\", [])[:num_results]\n",
    "    return [res[\"Text\"] for res in results if \"Text\" in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Google Search (Using SerpAPI) - Alternative\n",
    "def web_search_google(query, num_results=3):\n",
    "    url = \"https://serpapi.com/search\"\n",
    "    params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "    response = requests.get(url, params=params).json()\n",
    "    return [res[\"snippet\"] for res in response.get(\"organic_results\", []) if \"snippet\" in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Hybrid Retrieval (BM25 + FAISS + Web Search)\n",
    "def hybrid_retrieval(query, bm25, tokenized_corpus, vectorstore, docs, top_k=3):\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "    bm25_docs = [docs[i] for i in bm25_top_indices]\n",
    "    \n",
    "    faiss_docs = vectorstore.similarity_search(query, k=top_k)\n",
    "    web_results = web_search_duckduckgo(query, num_results=top_k)  # Replace with `web_search_google()` if needed\n",
    "\n",
    "    # Merge Results (Handling Duplicate Documents)\n",
    "    combined_docs = {doc.page_content: doc for doc in (bm25_docs + faiss_docs)}.values()\n",
    "    combined_texts = \"\\n\".join([doc.page_content for doc in combined_docs] + web_results)\n",
    "    \n",
    "    return combined_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Multi-Hop Online RAG\n",
    "def multi_hop_rag(query, retriever, llm, num_hops=2):\n",
    "    intermediate_query = query\n",
    "    context = \"\"\n",
    "\n",
    "    for hop in range(num_hops):\n",
    "        retrieved_texts = retriever(intermediate_query)\n",
    "        context += f\"\\n--- Retrieved Context (Hop {hop+1}) ---\\n{retrieved_texts}\\n\"\n",
    "\n",
    "        # Generate intermediate query refinement\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a knowledgeable AI assistant that provides factually accurate answers.\"),\n",
    "            HumanMessage(content=f\"Given this information, refine the question: {intermediate_query}\\n{context}\")\n",
    "        ]\n",
    "        response = llm(messages)\n",
    "        intermediate_query = response.content\n",
    "\n",
    "    # Final Answer Generation\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI assistant that provides the best answers by combining sources.\"),\n",
    "        HumanMessage(content=f\"Using this retrieved knowledge, answer the final query: {query}\\n{context}\")\n",
    "    ]\n",
    "    final_response = llm(messages)\n",
    "\n",
    "    return final_response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hybrid Retriever Wrapper\n",
    "def hybrid_retriever(query):\n",
    "    return hybrid_retrieval(query, bm25, tokenized_corpus, vectorstore, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: Day 1: Start your trip with a visit to iconic landmarks such as the Statue of Liberty and Times Square. You can also explore Central Park and enjoy a leisurely stroll or a boat ride in the lake.\n",
      "\n",
      "Day 2: Dedicate this day to exploring the world-renowned museums. Visit the Metropolitan Museum of Art in the morning and the Museum of Modern Art in the afternoon.\n",
      "\n",
      "Day 3: Visit the Empire State Building for breathtaking city views. Later, you can explore the vibrant neighborhoods of SoHo and Greenwich Village.\n",
      "\n",
      "Day 4: Spend the day exploring Brooklyn. Visit the Brooklyn Bridge, Brooklyn Botanic Garden, and enjoy the food scene at Smorgasburg.\n",
      "\n",
      "Day 5: Dedicate your last day to shopping and leisure. Visit Fifth Avenue for luxury shopping. End your trip with a Broadway show in the evening.\n",
      "\n",
      "Throughout your trip, you can dine at some of the best vegetarian restaurants in New York such as Superiority Burger, Dirt Candy, abcV, Jajaja, and Le Botaniste.\n",
      "\n",
      "Remember to follow general travel safety tips such as keeping a digital copy of your passport, using an RFID-blocking wallet for extra security, being aware of common tourist scams in major cities, and learning basic phrases in the local language.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üî• Run Multi-Hop Online RAG\n",
    "query = \"Plan a 5 days trip to New York?\"\n",
    "response = multi_hop_rag(query, hybrid_retriever, llm, num_hops=2)\n",
    "print(\"\\nFinal Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Enhancements in This RAG**\n",
    "‚úÖ **Online Search Integration**: Uses **DuckDuckGo API** (or **Google SerpAPI**) for real-time data.  \n",
    "‚úÖ **Multi-Hop Querying**: Iteratively refines search queries for better retrieval.  \n",
    "‚úÖ **Hybrid Retrieval**: Combines **BM25, FAISS, and Web Search** for comprehensive results.  \n",
    "‚úÖ **Improved OpenAI API Usage**: Ensures proper `ChatOpenAI` formatting.  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
